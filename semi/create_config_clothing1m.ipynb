{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da90a27-55a5-4ef5-ba4b-c263e72ae6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "\"\"\"\n",
    "Create the .yaml for each experiment\n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_configuration(cfg, cfg_file):\n",
    "    if 'lossnet' in cfg['algorithm']:\n",
    "        cfg['save_name'] = \"b_{alg}_{dataset}_{net}_{num_lb}_lr{lr}_{steplr}_bsz{batch_size}_{noise_type}_{noise_ratio}_{weakonly}_{esize}_{ebsz}_{metagoal}_{w_f}_{meta_lr}_beta{beta}_{seed}\".format(\n",
    "            alg=cfg['algorithm'],\n",
    "            dataset=cfg['dataset'],\n",
    "            net = cfg['net'],\n",
    "            num_lb=cfg['num_labels'],\n",
    "            lr=cfg['lr'],\n",
    "            steplr=cfg['steplr'],\n",
    "            batch_size = cfg['batch_size'],\n",
    "            noise_type=cfg['noise_type'],\n",
    "            noise_ratio =cfg['noise_ratio'],\n",
    "            weakonly = cfg['weak_only'],\n",
    "            esize =cfg['eval_set_size'],\n",
    "            ebsz =cfg['e_batch_size'],\n",
    "            metagoal = cfg['meta_goal'],\n",
    "            w_f=cfg['w_f'],\n",
    "            meta_lr=cfg['meta_lr'],\n",
    "            beta=cfg['beta'],\n",
    "            seed=cfg['seed']\n",
    "        )\n",
    "    else:\n",
    "        cfg['save_name'] = \"b_{alg}_{dataset}_{net}_{num_lb}_lr{lr}_{steplr}_bsz{batch_size}_{noise_type}_{noise_ratio}_{weakonly}_{esize}_{ebsz}_{metagoal}_{w_f}_beta{beta}_{seed}\".format(\n",
    "            # renew=cfg['renew'],\n",
    "            alg=cfg['algorithm'],\n",
    "            dataset=cfg['dataset'],\n",
    "            net = cfg['net'],\n",
    "            num_lb=cfg['num_labels'],\n",
    "            lr=cfg['lr'],\n",
    "            steplr=cfg['steplr'],\n",
    "            batch_size = cfg['batch_size'],\n",
    "            noise_type=cfg['noise_type'],\n",
    "            noise_ratio =cfg['noise_ratio'],\n",
    "            weakonly = cfg['weak_only'],\n",
    "            esize =cfg['eval_set_size'],\n",
    "            ebsz =cfg['e_batch_size'],\n",
    "            metagoal = cfg['meta_goal'],\n",
    "            w_f=cfg['w_f'],\n",
    "            beta=cfg['beta'],\n",
    "            seed=cfg['seed']\n",
    "        )\n",
    "    # resume\n",
    "    cfg['resume'] = False\n",
    "    cfg['load_path'] = '{}/{}/latest_model.pth'.format(cfg['save_dir'], cfg['save_name'])\n",
    "\n",
    "    alg_file = cfg_file + cfg['algorithm'] + '/'\n",
    "    if not os.path.exists(alg_file):\n",
    "        os.mkdir(alg_file)\n",
    "\n",
    "    print(alg_file + cfg['save_name'] + '.yaml')\n",
    "    with open(alg_file + cfg['save_name'] + '.yaml', 'w', encoding='utf-8') as w:\n",
    "        lines = []\n",
    "        for k, v in cfg.items():\n",
    "            line = str(k) + ': ' + str(v)\n",
    "            lines.append(line)\n",
    "        for line in lines:\n",
    "            w.writelines(line)\n",
    "            w.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_classific_config(alg, seed,\n",
    "                            dataset, net, num_classes, num_labels, img_size, \n",
    "                            port,meta_goal,threshold,noise_type,noise_ratio,meta_lr,beta):\n",
    "    cfg = {}\n",
    "    cfg['algorithm'] = alg\n",
    "\n",
    "    # save config\n",
    "    cfg['save_dir'] = './saved_models/cifar10_uda'\n",
    "    cfg['save_name'] = None\n",
    "    cfg['resume'] = False\n",
    "    cfg['load_path'] = None\n",
    "    cfg['overwrite'] = True\n",
    "    cfg['use_tensorboard'] = True\n",
    "\n",
    "    # algorithm config\n",
    "    cfg['epoch'] = 10\n",
    "    cfg['num_train_iter'] = 120000             #1048576         #2 ** 20\n",
    "    cfg['num_eval_iter'] = 500\n",
    "    cfg['num_labels'] = num_labels\n",
    "    cfg['batch_size'] = 64\n",
    "    cfg['eval_batch_size'] = 256\n",
    "    \n",
    "    if alg == 'fixmatch' or alg == 'fixmatch_lossnet':\n",
    "        cfg['hard_label'] = True\n",
    "        cfg['T'] = 0.5\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['uratio'] = 7\n",
    "    elif alg == 'adamatch':\n",
    "        cfg['hard_label'] = True\n",
    "        cfg['T'] = 0.5\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['ema_p'] = 0.999\n",
    "        cfg['uratio'] = 7\n",
    "    elif alg == 'flexmatch':\n",
    "        cfg['hard_label'] = True\n",
    "        cfg['T'] = 0.5\n",
    "        cfg['thresh_warmup'] = True\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['uratio'] = 7\n",
    "    elif alg == 'uda':\n",
    "        cfg['tsa_schedule'] = 'none'\n",
    "        cfg['T'] = 0.4\n",
    "        cfg['p_cutoff'] = 0.8\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['uratio'] = 7\n",
    "    elif alg == 'pseudolabel':\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['uratio'] = 1\n",
    "        cfg['unsup_warm_up'] = 0.4\n",
    "    elif alg == 'mixmatch':\n",
    "        cfg['uratio'] = 1\n",
    "        cfg['mixup_alpha'] = 0.5\n",
    "        cfg['T'] = 0.5\n",
    "        if dataset == 'cifar10':\n",
    "            cfg['ulb_loss_ratio'] = 75\n",
    "        elif dataset == 'cifar100':\n",
    "            cfg['ulb_loss_ratio'] = 150\n",
    "        else:\n",
    "            cfg['ulb_loss_ratio'] = 100\n",
    "        cfg['unsup_warm_up'] = 0.4 # 16000 / 1024 / 1024\n",
    "    elif alg == 'remixmatch':\n",
    "        cfg['mixup_alpha'] = 0.75\n",
    "        cfg['T'] = 0.5\n",
    "        cfg['kl_loss_ratio'] = 0.5\n",
    "        cfg['ulb_loss_ratio'] = 1.5\n",
    "        cfg['rot_loss_ratio'] = 0.5\n",
    "        cfg['unsup_warm_up'] = 1 / 64\n",
    "        cfg['uratio'] = 1\n",
    "    elif alg == 'crmatch':\n",
    "        cfg['hard_label'] = True\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['uratio'] = 7\n",
    "    elif alg == 'comatch':\n",
    "        cfg['hard_label'] = False\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['contrast_p_cutoff'] = 0.8 \n",
    "        cfg['contrast_loss_ratio'] = 1.0\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['proj_size'] = 64\n",
    "        cfg['queue_batch'] = 5\n",
    "        cfg['smoothing_alpha'] = 0.9\n",
    "        cfg['uratio'] = 7\n",
    "        cfg['T'] = 0.2\n",
    "        cfg['da_len'] = 32\n",
    "        \n",
    "        if dataset == 'stl10':\n",
    "            cfg['contrast_loss_ratio'] = 5.0\n",
    "\n",
    "        if dataset == 'imagenet':\n",
    "            cfg['p_cutoff'] = 0.6\n",
    "            cfg['contrast_p_cutoff'] = 0.3\n",
    "            cfg['contrast_loss_ratio'] = 10.0\n",
    "            cfg['ulb_loss_ratio'] = 10.0\n",
    "            cfg['smoothing_alpha'] = 0.9\n",
    "            cfg['T'] = 0.1\n",
    "            cfg['proj_size'] = 128\n",
    "\n",
    "    elif alg == 'simmatch':\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['in_loss_ratio'] = 1.0\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['proj_size'] = 128\n",
    "        cfg['K'] = 256\n",
    "        cfg['da_len'] = 32\n",
    "        cfg['smoothing_alpha'] = 0.9\n",
    "        cfg['uratio'] = 7\n",
    "        if dataset in ['cifar10', 'svhn',  'cifar100', 'stl10']:\n",
    "            cfg['T'] = 0.1\n",
    "        else:\n",
    "            cfg['T'] = 0.2\n",
    "    elif alg == 'meanteacher':\n",
    "        cfg['uratio'] = 1\n",
    "        cfg['ulb_loss_ratio'] = 50\n",
    "        cfg['unsup_warm_up'] = 0.4\n",
    "    elif alg == 'pimodel':\n",
    "        cfg['ulb_loss_ratio'] = 10\n",
    "        cfg['uratio'] = 1\n",
    "        cfg['unsup_warm_up'] = 0.4\n",
    "    elif alg == 'dash':\n",
    "        cfg['gamma'] = 1.27\n",
    "        cfg['C'] = 1.0001\n",
    "        cfg['rho_min'] = 0.05\n",
    "        cfg['num_wu_iter'] = 2048\n",
    "        cfg['T'] = 0.5\n",
    "        cfg['p_cutoff'] = 0.95\n",
    "        cfg['ulb_loss_ratio'] = 1.0\n",
    "        cfg['uratio'] = 7\n",
    "    elif alg == 'mpl':\n",
    "        cfg['tsa_schedule'] = 'none'\n",
    "        cfg['T'] = 0.7\n",
    "        cfg['p_cutoff'] = 0.6\n",
    "        cfg['ulb_loss_ratio'] = 8.0\n",
    "        cfg['uratio'] = 7\n",
    "        cfg['teacher_lr'] = 0.03\n",
    "        cfg['label_smoothing'] = 0.1\n",
    "        cfg['num_uda_warmup_iter'] = 5000\n",
    "        cfg['num_stu_wait_iter'] = 3000\n",
    "\n",
    "    # cfg['img']\n",
    "    cfg['ema_m'] = 0.999 #0.999\n",
    "    cfg['crop_ratio'] = 0.875\n",
    "    cfg['img_size'] = img_size\n",
    "\n",
    "    # optim config\n",
    "    cfg['optim'] = 'SGD'\n",
    "    cfg['lr'] = 0.03\n",
    "    cfg['momentum'] = 0.9\n",
    "    cfg['weight_decay'] = 0.0001\n",
    "    cfg['layer_decay'] = 1.0\n",
    "    cfg['amp'] = False\n",
    "    cfg['clip'] = 0.0\n",
    "    cfg['use_cat'] = True\n",
    "\n",
    "    # net config\n",
    "    cfg['net'] = net\n",
    "    cfg['net_from_name'] = False\n",
    "\n",
    "    # data config\n",
    "    cfg['data_dir'] = './data'\n",
    "    cfg['dataset'] = dataset\n",
    "    cfg['train_sampler'] = 'RandomSampler'\n",
    "    cfg['num_classes'] = num_classes\n",
    "    cfg['num_workers'] = 1\n",
    "\n",
    "    # basic config\n",
    "    cfg['seed'] = seed\n",
    "\n",
    "    # distributed config\n",
    "    cfg['world_size'] = 1\n",
    "    cfg['rank'] = 0\n",
    "    cfg['multiprocessing_distributed'] = False\n",
    "    cfg['dist_url'] = 'tcp://127.0.0.1:' + str(port)\n",
    "    cfg['dist_backend'] = 'nccl'\n",
    "    cfg['gpu'] = None\n",
    "\n",
    "    # other config\n",
    "    cfg['overwrite'] = True\n",
    "    cfg['amp'] = False\n",
    "\n",
    "   \n",
    "    \n",
    "    cfg['lr']= 0.01                       #0.0005                    #0.001     #0.0005 0.01 \n",
    "    cfg['beta'] = beta\n",
    "    cfg['num_train_iter'] = 60000 \n",
    "    cfg['steplr']=True\n",
    "    cfg['batch_size']= 32\n",
    "    cfg['noise_type'] = noise_type\n",
    "    cfg['noise_ratio'] = noise_ratio\n",
    "    cfg['weak_only']=False\n",
    "    cfg['eval_set_size']= 7000\n",
    "    cfg['e_batch_size']= 100\n",
    "    cfg['meta_goal']= meta_goal\n",
    "    cfg['w_f']= 'uni'\n",
    "    cfg['threshold']=threshold\n",
    "    cfg['use_pretrain']=False\n",
    "    cfg['renew']= None\n",
    "    cfg['ema_m'] = 0.999\n",
    "    cfg['meta_lr'] = meta_lr\n",
    "    # cfg['relabel']=False\n",
    "    return cfg\n",
    "\n",
    "\n",
    "\n",
    "# prepare the configuration for baseline model, use_penalty == False\n",
    "def exp_classific_cv(label_amount,meta_goal,threshold,noise_type,noise_ratio,meta_lr,beta):\n",
    "    config_file = r'./config/classic_cv_meta/'\n",
    "    save_path = r'./saved_models/mnist'\n",
    "\n",
    "    if not os.path.exists(config_file):\n",
    "        os.mkdir(config_file)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    # algs=['fullysupervised']\n",
    "    algs=['fullysupervised_lossnet']\n",
    "    # algs = ['flexmatch', 'fixmatch', 'uda', 'pseudolabel', 'fullysupervised', 'remixmatch', 'mixmatch', 'meanteacher',\n",
    "    #         'pimodel', 'vat', 'dash', 'crmatch', 'comatch', 'simmatch', 'adamatch']\n",
    "    # datasets = ['cifar100', 'svhn', 'stl10', 'cifar10']\n",
    "    datasets = ['clothing1m']\n",
    "    # seeds = [0, 1, 2] \n",
    "    seeds = [2,3,8,11,13]\n",
    "\n",
    "\n",
    "    dist_port = range(10001, 11120, 1)\n",
    "    count = 0\n",
    "\n",
    "    for alg in algs:\n",
    "        for dataset in datasets:\n",
    "            for seed in seeds:\n",
    "                \n",
    "                # change the configuration of each dataset\n",
    "                if dataset == 'cifar10':\n",
    "                    # net = 'WideResNet'\n",
    "                    num_classes = 10\n",
    "                    num_labels = label_amount\n",
    "                    weight_decay = 5e-4\n",
    "                    net = 'wrn_28_10'\n",
    "                    # weight_decay = 1e-3\n",
    "                    # net='resnet34'\n",
    "                    # weight_decay=1e-3\n",
    "                    img_size = 32\n",
    "\n",
    "                elif dataset == 'cifar100':\n",
    "                    # net = 'WideResNet's\n",
    "                    num_classes = 100\n",
    "                    num_labels = label_amount\n",
    "                    weight_decay = 1e-3\n",
    "                    # depth = 28\n",
    "                    # widen_factor = 8\n",
    "                    net = 'wrn_28_10'\n",
    "                    # net='resnet34'\n",
    "                    # weight_decay = 5e-4\n",
    "                    img_size = 32 \n",
    "                if dataset == 'clothing1m':\n",
    "                    # net = 'WideResNet'\n",
    "                    num_classes = 14 \n",
    "                    num_labels = label_amount\n",
    "                    # weight_decay = 5e-4\n",
    "                    # net = 'wrn_28_10'\n",
    "                    weight_decay = 1e-3\n",
    "                    net='resnet50'\n",
    "                    # weight_decay=1e-3\n",
    "                    img_size = 256\n",
    "                    \n",
    "                elif dataset == 'svhn':\n",
    "                    # net = 'WideResNet'\n",
    "                    num_classes = 10\n",
    "                    num_labels = label_amount\n",
    "                    weight_decay = 5e-4\n",
    "                    # depth = 28\n",
    "                    # widen_factor = 2\n",
    "                    net = 'wrn_28_2'\n",
    "                    img_size = 32\n",
    "\n",
    "                elif dataset == 'stl10':\n",
    "                    # net = 'WideResNetVar'\n",
    "                    num_classes = 10\n",
    "                    num_labels = label_amount\n",
    "                    weight_decay = 5e-4\n",
    "                    net = 'wrn_var_37_2'\n",
    "                    img_size = 96\n",
    "                elif dataset == 'mnist':\n",
    "                    # net = 'WideResNetVar'\n",
    "                    num_classes = 10\n",
    "                    num_labels = label_amount\n",
    "                    weight_decay = 5e-4\n",
    "                    net = 'LeNet'\n",
    "                    img_size = 32\n",
    "\n",
    "                elif dataset == 'imagenet':\n",
    "                    if alg not in ['fixmatch', 'flexmatch']:\n",
    "                        continue\n",
    "                    net = 'resnet50'\n",
    "                    num_classes = 1000\n",
    "                    num_labels = 100000  # 128000\n",
    "                    weight_decay = 3e-4\n",
    "\n",
    "                port = dist_port[count]\n",
    "                \n",
    "                \n",
    "                # prepare the configuration file\n",
    "                cfg = create_classific_config(alg, seed,\n",
    "                                              dataset, net, num_classes, num_labels, img_size, \n",
    "                                              port,meta_goal,threshold,noise_type,noise_ratio,meta_lr,beta)\n",
    "                count += 1\n",
    "                create_configuration(cfg, config_file)\n",
    "                # print(cfg['save_name'])\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # if not os.path.exists('./saved_models/classic_cv/'):\n",
    "#     #     os.mkdir('./saved_models/classic_cv/')\n",
    "#     if not os.path.exists('./config/classic_cv/'):\n",
    "#         os.mkdir('./config/classic_cv/')\n",
    "\n",
    "#     # classific cv\n",
    "#     label_amount = {'s': [40, 400, 40, 40],\n",
    "#                     'm': [250, 2500, 250, 250],\n",
    "#                     'l': [4000, 10000, 1000, 1000]}\n",
    "\n",
    "    # for i in label_amount:\n",
    "    #     exp_classific_cv(label_amount=label_amount[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc03a8e9-c2ae-4c39-9206-c93548d5c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if not os.path.exists('./saved_models/classic_cv/'):\n",
    "    #     os.mkdir('./saved_models/classic_cv/')\n",
    "if not os.path.exists('./config/classic_cv_meta/'):\n",
    "        os.mkdir('./config/classic_cv_meta/')\n",
    "\n",
    "label_amount_l=[192000]\n",
    "# meta_goal_l= ['feat_exp', 'feat_expr', 'feat_expN', 'feat_expNr', 'feat_expno1', 'feat_expno1r', 'feat_expno1N', 'feat_expno1Nr']\n",
    "# meta_goal_l= ['feat_exp_ws_','feat_exp_ws']\n",
    "# meta_goal_l=['feat_expno1','feat_expno1N']\n",
    "meta_goal_l=['cen']\n",
    "# feat_expno1N\n",
    "noise_type_l =  ['human']\n",
    "# noise_type_l =  ['human_worst','human_aggre','human_random']\n",
    "\n",
    "noise_ratio_l = [0]\n",
    "# noise_l = ['human_worst_0','asy_0.4']\n",
    "threshold_l=[0]\n",
    "meta_lr_l=[0.001] #0.0001 0.00001 1e-05\n",
    "beta_l=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4528ea1-2dd6-44ab-aa8e-7e9f23b9020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./config/classic_cv_meta/fullysupervised_lossnet/b_fullysupervised_lossnet_clothing1m_resnet50_192000_lr0.01_True_bsz32_human_0_False_7000_100_cen_uni_0.001_beta0_2.yaml\n",
      "./config/classic_cv_meta/fullysupervised_lossnet/b_fullysupervised_lossnet_clothing1m_resnet50_192000_lr0.01_True_bsz32_human_0_False_7000_100_cen_uni_0.001_beta0_3.yaml\n",
      "./config/classic_cv_meta/fullysupervised_lossnet/b_fullysupervised_lossnet_clothing1m_resnet50_192000_lr0.01_True_bsz32_human_0_False_7000_100_cen_uni_0.001_beta0_8.yaml\n",
      "./config/classic_cv_meta/fullysupervised_lossnet/b_fullysupervised_lossnet_clothing1m_resnet50_192000_lr0.01_True_bsz32_human_0_False_7000_100_cen_uni_0.001_beta0_11.yaml\n",
      "./config/classic_cv_meta/fullysupervised_lossnet/b_fullysupervised_lossnet_clothing1m_resnet50_192000_lr0.01_True_bsz32_human_0_False_7000_100_cen_uni_0.001_beta0_13.yaml\n"
     ]
    }
   ],
   "source": [
    "for label_amount in label_amount_l:\n",
    "    for meta_goal in meta_goal_l:\n",
    "        for threshold in threshold_l:\n",
    "            for noise_type in noise_type_l:\n",
    "                for noise_ratio in noise_ratio_l:\n",
    "                    for meta_lr in meta_lr_l:\n",
    "                        for beta in beta_l:\n",
    "                            exp_classific_cv(label_amount,meta_goal,threshold,noise_type,noise_ratio,meta_lr,beta)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
