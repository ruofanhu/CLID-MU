{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "# import torch.nn as nn\n",
    "# import IPython\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "# from utils import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import json\n",
    "import collections\n",
    "from itertools import islice, chain\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Optional, Callable, Tuple, Dict, Union\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    if checkpoint_path and os.path.isfile(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    else:\n",
    "        checkpoint = load_state_dict_from_url(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    \n",
    "    orig_state_dict = checkpoint['model']\n",
    "    new_state_dict = {}\n",
    "    for key, item in orig_state_dict.items():\n",
    "\n",
    "        \n",
    "        if key.startswith('module'):\n",
    "            key = '.'.join(key.split('.')[1:])\n",
    "        \n",
    "        # TODO: better ways\n",
    "        if key.startswith('fc') or key.startswith('classifier') or key.startswith('mlp') or key.startswith('head'):\n",
    "            continue\n",
    "            \n",
    "        # check vit and interpolate\n",
    "        # if isinstance(model, VisionTransformer) and 'patch_emb'\n",
    "\n",
    "        if key == 'pos_embed':\n",
    "            posemb_new = model.pos_embed.data\n",
    "            posemb = item\n",
    "            item = resize_pos_embed_vit(posemb, posemb_new)\n",
    "\n",
    "        new_state_dict[key] = item \n",
    "    \n",
    "    match = model.load_state_dict(new_state_dict, strict=False)\n",
    "    print(match)\n",
    "    return model\n",
    "\n",
    "class ModelWrapper(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    " \n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor(X)\n",
    "            self.model.eval()\n",
    "            logits = self.model(X)['logits']\n",
    "            m = nn.Softmax(dim=1)\n",
    "            preds = m(logits)\n",
    "            preds = preds.to('cpu').detach().numpy()\n",
    "            return np.argmax(preds, axis=1)\n",
    "\n",
    "        \n",
    "class ModelWrapper_feature(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    " \n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor(X)\n",
    "            self.model.eval()\n",
    "            logits = self.model(X)['logits']\n",
    "            m = nn.Softmax(dim=1)\n",
    "            preds = m(logits)\n",
    "            preds = preds.to('cpu').detach().numpy()\n",
    "            return np.argmax(preds, axis=1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir=os.path.join(save_dir ,save_name)\n",
    "\n",
    "weight_log = torch.load(os.path.join(path_dir,'data_weight_log.pt'))\n",
    "\n",
    "\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "scalars =['train/sup_loss', 'train/sup_loss_true', 'train/unsup_loss', 'train/total_loss', 'train/mask_ratio', 'lr', 'train/prefecth_time', \\\n",
    "          'train/run_time', 'eval/loss', 'eval/top-1-acc', 'eval/balanced_acc', 'eval/precision', 'eval/recall', 'eval/F1', 'lid_logits', 'lid_feat',\\\n",
    "          'unl_ce_loss', 'tn_logits', 'fp_logits', 'fn_logits', 'tp_logits', 'tn_feat', 'fp_feat', 'fn_feat', 'tp_feat', 'tn_ce', 'fp_ce', 'fn_ce', 'tp_ce', \\\n",
    "          'f1_logits', 'f1_feat', 'f1_ce'] #'feat_std','cov_loss'\n",
    "\n",
    "def parse_tensorboard(path_event, scalars):\n",
    "    \"\"\"returns a dictionary of pandas dataframes for each requested scalar\"\"\"\n",
    "    ea = event_accumulator.EventAccumulator(\n",
    "        path_event,\n",
    "        size_guidance={event_accumulator.SCALARS: 0},\n",
    "    )\n",
    "    _absorb_print = ea.Reload()\n",
    "    scalars = ea.Tags()[\"scalars\"]\n",
    "    # make sure the scalars are in the event accumulator tags\n",
    "    assert all(\n",
    "        s in ea.Tags()[\"scalars\"] for s in scalars\n",
    "    ), \"some scalars were not found in the event accumulator\"\n",
    "    return {k: pd.DataFrame(ea.Scalars(k)) for k in scalars}\n",
    "\n",
    "event_name = os.listdir(os.path.join(path_dir,'tensorboard'))[-1]\n",
    "\n",
    "path_event = os.path.join(path_dir,'tensorboard', event_name)\n",
    "\n",
    "log_ = parse_tensorboard(path_event, scalars)\n",
    "print(weight_log.keys(), '\\n',log_.keys())\n",
    "\n",
    "from utils import *\n",
    "def clean_ratio_batch(log_,var_name):\n",
    "    N = log_['lid_80/tn_{}'.format(var_name)]['value']+ log_['lid_80/fp_{}'.format(var_name)]['value']\n",
    "    all_ = N + log_['lid_80/tp_{}'.format(var_name)]['value']+log_['lid_80/fn_{}'.format(var_name)]['value']\n",
    "    return N/all_\n",
    "def metric_smoothing(list_metrics):\n",
    "    smoothing_alpha=0.9\n",
    "    s_list_metrics=[]\n",
    "    p_l=0\n",
    "    for i in range(len(list_metrics)):\n",
    "        p_l = smoothing_alpha *p_l + (1 - smoothing_alpha)* list_metrics[i]\n",
    "        s_list_metrics.append(p_l/(1 - smoothing_alpha**(i+1)))\n",
    "    return s_list_metrics\n",
    "\n",
    "smoothing_alpha =0.9\n",
    "def smoothing_metrics(precision_logits, recall_logits,f1_logits):\n",
    "    precision_logits_smooth=[]\n",
    "    recall_logits_smooth=[]\n",
    "    f1_logits_smooth=[]\n",
    "    smoothing_alpha=0.9\n",
    "    p_l=0\n",
    "    r_l=0\n",
    "    f_l=0\n",
    "\n",
    "    for i in range(len(precision_logits)):\n",
    "        p_l = smoothing_alpha *p_l + (1 - smoothing_alpha)* precision_logits[i]\n",
    "        precision_logits_smooth.append(p_l/(1 - smoothing_alpha**(i+1)))\n",
    "\n",
    "        r_l = smoothing_alpha *r_l + (1 - smoothing_alpha)* recall_logits[i]\n",
    "        recall_logits_smooth.append(r_l/(1 - smoothing_alpha**(i+1)))\n",
    "        f_l = smoothing_alpha *f_l + (1 - smoothing_alpha)* f1_logits[i]\n",
    "        f1_logits_smooth.append(r_l/(1 - smoothing_alpha**(i+1)))\n",
    "        \n",
    "    return precision_logits_smooth, recall_logits_smooth, f1_logits_smooth\n",
    "\n",
    "\n",
    "def get_g_clean_noisy(weight_log,key):\n",
    "    noise_g_logits=[]\n",
    "\n",
    "    clean_g_logits=[]\n",
    "    for i,batch_idx in enumerate(weight_log['sample_idx']):\n",
    "        noise_g_logits.append([weight_log[key][i][j].item() for j,idx_ in enumerate(batch_idx) if idx_.item() not in weight_log['clean_indices']])\n",
    "\n",
    "        clean_g_logits.append([weight_log[key][i][j].item() for j,idx_ in enumerate(batch_idx) if idx_.item() in weight_log['clean_indices'] ])\n",
    "    return noise_g_logits,clean_g_logits\n",
    "\n",
    "\n",
    "def cal_metric(weight_log,key):\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    f1=[]\n",
    "\n",
    "    # noisy label=1, clean label=0\n",
    "    for i in range(len(weight_log['iteration'])):\n",
    "        pred = [1 if w<0 else 0 for w in weight_log[key][i].numpy() ]\n",
    "        truth =[0 if idx_.item() in weight_log['clean_indices'] else 1 for idx_ in weight_log['sample_idx'][i]]\n",
    "        r = recall_score(truth,pred,average='binary')\n",
    "        p = precision_score(truth,pred,average='binary')\n",
    "        f1_ = f1_score(truth,pred,average='binary')\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f1_)\n",
    "    precision_s, recall_s, f1_s = smoothing_metrics(precision, recall,f1)\n",
    "    return precision, recall, f1, precision_s, recall_s, f1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(6,2, figsize=(18,30))\n",
    "ax1, ax2,ax3,ax4,ax5,ax6,ax7,ax8, ax9, ax10,ax11,ax12 = axes.ravel()\n",
    "\n",
    "steps=log_['train/sup_loss']['step']\n",
    "\n",
    "ax1.plot(steps, log_['train/sup_loss_weighted']['value'], label='train/sup_loss_weighted') #which is the training loss\n",
    "ax1.plot(steps, log_['train/sup_loss']['value'], label='train/sup_loss')\n",
    "ax1.plot(steps,log_['train/sup_loss_true']['value'], alpha=0.5,label='train/sup_loss_true')\n",
    "ax1.plot(steps,log_['train/sup_loss_true_weighted']['value'], alpha=0.5,c='orange',label='train/sup_loss_true_weighted')\n",
    "\n",
    "# ax1.plot(steps, log_['train/sup_loss_true']['value'], label='train/sup_loss_true')\n",
    "# ax1.plot(steps, log_['train/sup_loss_true_weighted']['value'], label='train/sup_loss_true_weighted')\n",
    "\n",
    "# ax1.plot(steps,log_['train/unsup_loss']['value'], label='train/unsup_loss')\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.legend()\n",
    "# ax1.set_ylim(0,0.28)\n",
    "ax1.set_title('Training Loss')\n",
    "\n",
    "# ax2.plot(steps,log_['train/sup_loss_true']['value'], alpha=0.5,label='train/sup_loss_true')\n",
    "ax2.plot(steps, log_['train/sup_loss_weighted']['value'], label='train/sup_loss_weighted') #which is the training loss\n",
    "ax2.plot(steps,log_['train/sup_loss_true_weighted']['value'], alpha=0.5,c='orange',label='train/sup_loss_true_weighted')\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "# ax2.set_ylim(0,0.28)\n",
    "\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.legend()\n",
    "ax2.set_title('Training Loss calculated with ground truth label')\n",
    "\n",
    "# ax2.plot(steps,log_['train/total_loss']['value'],label= 'train/total_loss')\n",
    "# ax2.set_ylabel(\"Loss\")\n",
    "# ax2.set_xlabel(\"Iteration\")\n",
    "# ax2.legend()\n",
    "# ax2.set_title('Total Training Loss')\n",
    "\n",
    "\n",
    "ax3.plot(steps,log_['eval/loss']['value'],label='test/loss')\n",
    "ax3.set_xlabel(\"Iteration\")\n",
    "ax3.set_ylabel(\"Loss\")\n",
    "# ax3.set_ylim(0,v0.28)\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_title('Test Set - Loss')\n",
    "\n",
    "ax4.plot(steps,log_['eval/top-1-acc']['value'] ,label='test/top-1-acc')\n",
    "ax4.set_xlabel(\"Iteration\")\n",
    "ax4.set_ylabel(\"Acc\")\n",
    "ax4.legend()\n",
    "ax4.set_title('Test Set - Acc')\n",
    "\n",
    "ax5.plot(steps,log_['eval/balanced_acc']['value'],label='test/balanced_acc')\n",
    "ax5.set_xlabel(\"Iteration\")\n",
    "ax5.set_ylabel(\"Acc\")\n",
    "ax5.legend()\n",
    "ax5.set_title('Test Set balanced_acc')\n",
    "\n",
    "\n",
    "\n",
    "ax6.plot(log_['train_val_acc']['step'],log_['train_val_acc']['value'],label='val/top-1-acc')\n",
    "ax6.set_xlabel(\"Iteration\")\n",
    "ax6.set_ylabel(\"Validation Acc\")\n",
    "ax6.legend()\n",
    "ax6.set_title('Validation Set - Acc')\n",
    "\n",
    "ax7.plot(weight_log['unl_ce_loss'],label='val/loss')\n",
    "ax7.set_xlabel(\"Iteration\")\n",
    "ax7.set_ylabel(\"Loss\")\n",
    "# ax7.set_ylim(0,0.28)\n",
    "\n",
    "ax7.legend()\n",
    "ax7.set_title(\"Validation Set - Loss\")\n",
    "\n",
    "\n",
    "\n",
    "ax8.plot([i.mean() for i in weight_log['labi_lid_feat_l2']],label='LID(feat) l2')\n",
    "ax8.set_xlabel(\"Iteration\")\n",
    "ax8.set_ylabel(\"LID\")\n",
    "ax8.legend()\n",
    "ax8.set_title('Training Set - LID')\n",
    "\n",
    "\n",
    "ax9.plot(weight_log['lid_feat_l2'] ,label='Validation LID(feat) l2')\n",
    "ax9.set_xlabel(\"Iteration\")\n",
    "ax9.set_ylabel(\"LID\")\n",
    "ax9.legend()\n",
    "ax9.set_title('LID(feat) of Validation set')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax11.plot(log_['train/acc_lb']['step'],log_['train/acc_lb']['value'],label='train/acc')\n",
    "ax11.plot(log_['train/acc_lb_true']['step'],log_['train/acc_lb_true']['value'],label='train/acc_true')\n",
    "ax11.set_xlabel(\"Iteration\")\n",
    "ax11.set_ylabel(\"Acc\")\n",
    "ax11.legend()\n",
    "ax11.set_title('Training Set - Acc')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if w_type=='logits' :    \n",
    "    prefix = 'lid_logits_l2'\n",
    "elif w_type=='feat'or w_type=='n':\n",
    "    prefix = 'lid_feat_l2'\n",
    "else:\n",
    "    prefix = 'ce_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_logits, recall_logits, f1_logits, precision_logits_s, recall_logits_s, f1_logits_s = cal_metric(weight_log,'w_lid_{}_l2'.format(prefix))\n",
    "# plt.plot(weight_log['iteration'], f1_logits, label='f1 feat l2')\n",
    "# plt.plot(weight_log['iteration'], f1_logits_s, label='f1 logits feat l2')\n",
    "\n",
    "# plt.ylabel(\"F1\")\n",
    "# plt.ylim(0,1)\n",
    "# plt.legend()\n",
    "# plt.title('F1 for Mislabeled Samples Identification based on Feature l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['lid_feat_l2']:\n",
    "    print('------------------------------------------------',prefix)\n",
    "    w_noise_lid_logits, w_clean_lid_logits = get_g_clean_noisy(weight_log,'w_{}'.format(prefix))\n",
    "    w_all = weight_log['w_{}'.format(prefix)]\n",
    "    weight_log['w_lid_l2_nor'] =[]\n",
    "\n",
    "    for it in range(len(w_all)):\n",
    "        total_meta = torch.maximum(torch.zeros(len(w_all[it])),w_all[it])\n",
    "        total_meta /= torch.sum(total_meta)\n",
    "        weight_log['w_lid_l2_nor'].append(total_meta)\n",
    "    w_noise_lid_logits_n, w_clean_lid_logits_n=get_g_clean_noisy(weight_log,'w_lid_l2_nor')\n",
    "\n",
    "    noise_w_avg = [np.array(i).mean() for i in w_noise_lid_logits]\n",
    "    noise_w_min = [np.array(i).min() for i in w_noise_lid_logits]\n",
    "    noise_w_max = [np.array(i).max() for i in w_noise_lid_logits]\n",
    "\n",
    "    clean_w_avg = [np.array(i).mean() for i in w_clean_lid_logits]\n",
    "    clean_w_max = [np.array(i).max() for i in w_clean_lid_logits]\n",
    "    clean_w_min = [np.array(i).min() for i in w_clean_lid_logits]\n",
    "\n",
    "    s=len(clean_w_avg)\n",
    "    fig, axes = plt.subplots(1,2, figsize=(15,5),sharey=True)\n",
    "    ax1, ax2 = axes.ravel()\n",
    "\n",
    "    ax1.plot(clean_w_avg[:s],label='clean_w_avg')\n",
    "    ax1.plot(clean_w_max[:s],label='clean_w_max')\n",
    "    ax1.plot(clean_w_min[:s],label='clean_w_min')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Training Raw Weights -Clean examples')\n",
    "    ax1.set_ylabel('Raw Weights')\n",
    "    ax1.set_xlabel('iteration')\n",
    "\n",
    "    ax2.plot(noise_w_avg[:s],label='noisy_w_avg')\n",
    "    ax2.plot(noise_w_max[:s],label='noisy_w_max')\n",
    "    ax2.plot(noise_w_min[:s],label='noisy_w_min')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Training Raw Weights -Noisy examples')\n",
    "    ax1.set_ylabel('Raw Weights')\n",
    "    ax1.set_xlabel('iteration')\n",
    "\n",
    "    plt.show()\n",
    "    noise_w_avg = [np.array(i).mean() for i in w_noise_lid_logits_n]\n",
    "    noise_w_min = [np.array(i).min() for i in w_noise_lid_logits_n]\n",
    "    noise_w_max = [np.array(i).max() for i in w_noise_lid_logits_n]\n",
    "\n",
    "    clean_w_avg = [np.array(i).mean() for i in w_clean_lid_logits_n]\n",
    "    clean_w_max = [np.array(i).max() for i in w_clean_lid_logits_n]\n",
    "    clean_w_min = [np.array(i).min() for i in w_clean_lid_logits_n]\n",
    "\n",
    "    clean_w_avg_s = metric_smoothing(clean_w_avg)\n",
    "    clean_w_max_s =metric_smoothing(clean_w_max)\n",
    "\n",
    "    noise_w_avg_s = metric_smoothing(noise_w_avg)\n",
    "    noise_w_max_s =metric_smoothing(noise_w_max)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(2,2, figsize=(15,10),sharey=True)\n",
    "    ax1, ax2,ax3,ax4 = axes.ravel()\n",
    "\n",
    "    ax1.plot(clean_w_avg[:s],label='clean_w_avg')\n",
    "    ax1.plot(clean_w_max[:s],label='clean_w_max')\n",
    "    # ax1.plot(clean_w_min,label='clean_w_min')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Training Normalized Weights -Clean examples')\n",
    "    ax1.set_ylabel('Normalized Weights')\n",
    "    ax1.set_xlabel('iteration')\n",
    "\n",
    "    ax2.plot(noise_w_avg[:s],label='noisy_w_avg')\n",
    "    ax2.plot(noise_w_max[:s],label='noisy_w_max')\n",
    "    # ax2.plot(noise_w_min,label='noisy_w_min')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Training Normalized Weights -Noisy examples')\n",
    "    ax1.set_ylabel('Normalized Weights')\n",
    "    ax1.set_xlabel('iteration')\n",
    "\n",
    "\n",
    "    ax3.plot(clean_w_avg_s[:s],label='clean_w_avg_s')\n",
    "    ax3.plot(clean_w_max_s[:s],label='clean_w_max_s')\n",
    "    ax3.plot(noise_w_avg_s[:s],label='noisy_w_avg_s')\n",
    "\n",
    "    # ax1.plot(clean_w_min,label='clean_w_min')\n",
    "\n",
    "    ax3.legend()\n",
    "    ax3.set_title('Training Normalized Weights (Smooth) -Clean examples')\n",
    "    ax3.set_ylabel('Normalized Weights')\n",
    "    ax3.set_xlabel('iteration')\n",
    "\n",
    "    ax4.plot(noise_w_avg_s[:s],label='noisy_w_avg_s')\n",
    "    ax4.plot(noise_w_max_s[:s],label='noisy_w_max_s')\n",
    "    # ax2.plot(noise_w_min,label='noisy_w_min')\n",
    "    ax4.legend()\n",
    "    ax4.set_title('Training Normalized Weights (Smooth) -Noisy examples')\n",
    "    ax4.set_ylabel('Normalized Weights')\n",
    "    ax4.set_xlabel('iteration')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('------------------------------------------------',prefix)\n",
    "    w_noise_lid_logits, w_clean_lid_logits = get_g_clean_noisy(weight_log,'w_{}'.format(prefix))\n",
    "    it_perepo= num_labels/batch_size\n",
    "    s_= int(it_perepo/2)\n",
    "\n",
    "    # iteration_l =list(range(0,100*int(it_perepo),max(s_,1)))\n",
    "    iteration_l =list(range(0,200,2))\n",
    "\n",
    "    # iteration_l=list(range(40,50))\n",
    "    fig, axes = plt.subplots(8, 5, tight_layout=True,sharey=True,figsize=(15.5,21))\n",
    "    n_bins=10\n",
    "    for row in axes:\n",
    "        for col in row:\n",
    "            if iteration_l:\n",
    "                i = iteration_l.pop(0)\n",
    "                col.hist(w_clean_lid_logits[i], bins=n_bins, alpha =0.5,label ='clean_weight')\n",
    "                col.hist(w_noise_lid_logits[i], bins=n_bins,alpha =0.5,label ='noisy_weight',color='orange')\n",
    "                col.set_xlabel(\"weight\")\n",
    "                col.set_ylabel(\"Frequency\")\n",
    "                col.set_title('Iteration %i: weight '%(i),y=1.05 )\n",
    "\n",
    "                col.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    iteration_l =list(range(0,200,2))\n",
    "    fig, axes = plt.subplots(8, 5, tight_layout=True,sharey=True,figsize=(15.5,21))\n",
    "    n_bins=10\n",
    "    for row in axes:\n",
    "        for col in row:\n",
    "            if iteration_l:\n",
    "                i = iteration_l.pop(0)\n",
    "                col.hist(w_clean_lid_logits_n[i], bins=n_bins, alpha =0.5,label ='clean_weight')\n",
    "                col.hist(w_noise_lid_logits_n[i], bins=n_bins,alpha =0.5,label ='noisy_weight',color='orange')\n",
    "                col.set_xlabel(\"weight\")\n",
    "                col.set_ylabel(\"Frequency\")\n",
    "                col.set_title('Iteration %i: Normalized weight '%(i),y=1.05 )\n",
    "\n",
    "                col.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further investigate the relatonship between LID(xi) and Noisy label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_keys(['true_label', 'train_labels', 'clean_indices', 'iteration', 'sample_idx', 'w_ce_loss', 'w_lid_logits_l2', 'w_lid_feat_l2', 'w_lid_logits_cos', 'w_lid_feat_cos', 'lid_feat_l2', 'lid_feat_cos', 'lid_logits_l2', 'lid_logits_cos', 'unl_ce_loss', 'labi_loss', 'labi_lid_logits_l2', 'labi_lid_feat_l2', 'labi_lid_logits_cos', 'labi_lid_feat_cos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_loss_feat,clean_loss_feat = get_g_clean_noisy(weight_log,'labi_loss')\n",
    "noise_lidfl2_feat,clean_lidfl2_feat = get_g_clean_noisy(weight_log,'labi_lid_logits_l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_loss_avg = [np.array(i).mean()/128 for i in clean_loss_feat]\n",
    "noise_loss_avg = [np.array(i).mean()/128 for i in noise_loss_feat]\n",
    "clean_loss_max = [np.array(i).max()/128 for i in clean_loss_feat]\n",
    "clean_loss_min = [np.array(i).min()/128 for i in clean_loss_feat]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(11,4), tight_layout=True, sharey=True,sharex=True)\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(clean_loss_avg, c='green',label='clean_loss_avg') \n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.legend()\n",
    "# ax1.set_ylim(0,0.28)\n",
    "ax1.set_title('Raw training Loss - clean')\n",
    "\n",
    "ax2.plot(noise_loss_avg, c='blue',label='mislabeled_loss_avg') \n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.legend()\n",
    "ax2.set_title('Raw training Loss - mislabeled')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(clean_loss_avg,label='clean_loss_avg',c='green')\n",
    "plt.plot(noise_loss_avg, c='blue',label='mislabeled_loss_avg')\n",
    "plt.title('Training Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('iteration')\n",
    "# plt.ylim(0,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighed Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'lid_feat_l2'\n",
    "w_all_ = weight_log['w_{}'.format(prefix)]\n",
    "# weight_log['w_lid_l2_minmax'] = []\n",
    "weight_log['weighted_loss'] = []\n",
    "\n",
    "for it in range(len(w_all_)):\n",
    "    total_meta_ = (w_all_[it]-w_all_[it].min())/(w_all_[it].max()-w_all_[it].min())\n",
    "    total_meta_ /= torch.sum(total_meta_)\n",
    "    weight_log['weighted_loss'].append(total_meta_*weight_log['labi_loss'][it])\n",
    "\n",
    "    \n",
    "noise_weighted_loss_feat,clean_weighted_loss_feat = get_g_clean_noisy(weight_log,'weighted_loss')\n",
    "\n",
    "clean_wloss_avg = [np.array(i).mean() for i in clean_weighted_loss_feat]\n",
    "noise_wloss_avg = [np.array(i).mean() for i in noise_weighted_loss_feat]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(11,4), tight_layout=True, sharey=True,sharex=True)\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(clean_wloss_avg, c='green',label='clean_weighted_loss_avg') \n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.legend()\n",
    "# ax1.set_ylim(0,0.28)\n",
    "ax1.set_title('Weighted training Loss - clean')\n",
    "\n",
    "ax2.plot(noise_wloss_avg, c='blue',label='mislabeled_weighted_loss_avg') \n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.legend()\n",
    "ax2.set_title('Weighted taining Loss - mislabeled')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(clean_wloss_avg,label='clean_weighted_loss_avg',c='green')\n",
    "plt.plot(noise_wloss_avg, c='blue',label='mislabeled_weighted_loss_avg')\n",
    "plt.title('Weighted Training Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('iteration')\n",
    "# plt.ylim(0,2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lid_avg = [np.array(i).mean() for i in clean_lidfl2_feat]\n",
    "noise_lid_avg = [np.array(i).mean() for i in noise_lidfl2_feat]\n",
    "clean_lid_max = [np.array(i).max() for i in clean_lidfl2_feat]\n",
    "clean_lid_min = [np.array(i).min() for i in clean_lidfl2_feat]\n",
    "\n",
    "plt.plot(clean_lid_avg,label='clean_lid_avg')\n",
    "plt.plot(clean_lid_max,label='clean_lid_max')\n",
    "plt.plot(clean_lid_min,label='clean_lid_min')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Training LID(logits) -Clean examples')\n",
    "plt.ylabel('LID')\n",
    "plt.xlabel('iteration')\n",
    "# plt.ylim(0,2)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(noise_lid_avg,label='noise_lid_avg', c='blue')\n",
    "plt.title('Training LID(logits) - Noisy examples')\n",
    "plt.ylabel('LID')\n",
    "# plt.xlabel('iteration')\n",
    "# plt.ylim(0,2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_lidfl2_feat,clean_lidfl2_feat = get_g_clean_noisy(weight_log,'labi_lid_feat_l2')\n",
    "clean_lid_avg_ = [np.array(i).mean() for i in clean_lidfl2_feat]\n",
    "noise_lid_avg_ = [np.array(i).mean() for i in noise_lidfl2_feat]\n",
    "clean_lid_max_ = [np.array(i).max() for i in clean_lidfl2_feat]\n",
    "clean_lid_min_ = [np.array(i).min() for i in clean_lidfl2_feat]\n",
    "\n",
    "plt.plot(clean_lid_avg_,label='clean_lid_avg')\n",
    "plt.plot(clean_lid_max_,label='clean_lid_max')\n",
    "plt.plot(clean_lid_min_,label='clean_lid_min')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Training LID(feat) -Clean examples')\n",
    "plt.ylabel('LID')\n",
    "plt.xlabel('iteration')\n",
    "# plt.ylim(0,2)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(noise_lid_avg_,label='noise_lid_avg', c='blue')\n",
    "plt.title('Training LID(feat) - Noisy examples')\n",
    "plt.ylabel('LID')\n",
    "# plt.xlabel('iteration')\n",
    "# plt.ylim(0,2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted loss\n",
    "it_perepo= num_labels/batch_size\n",
    "s_= int(it_perepo/2)\n",
    "\n",
    "iteration_l =list(range(0,100*int(it_perepo),max(s_,1)))\n",
    "# iteration_l=list(range(40,50))\n",
    "fig, axes = plt.subplots(8, 5, tight_layout=True,sharex=False,sharey=True,figsize=(15.5,21))\n",
    "n_bins=10\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        if iteration_l:\n",
    "            i = iteration_l.pop(0)\n",
    "            col.hist(clean_weighted_loss_feat[i], bins=n_bins, alpha =0.5,label ='clean')\n",
    "            col.hist(noise_weighted_loss_feat[i], bins=n_bins,alpha =0.5,label ='noisy',color='orange')\n",
    "            col.set_xlabel(\"Loss\")\n",
    "            col.set_ylabel(\"Frequency\")\n",
    "            col.set_title('Iteration %i: Weighted Loss '%(i),y=1.05 )\n",
    "\n",
    "            col.legend(loc='best')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_perepo= num_labels/batch_size\n",
    "s_= int(it_perepo/2)\n",
    "\n",
    "iteration_l =list(range(0,100*int(it_perepo),max(s_,1)))\n",
    "# iteration_l=list(range(40,50))\n",
    "fig, axes = plt.subplots(8, 5, tight_layout=True,sharex=True,sharey=True,figsize=(15.5,21))\n",
    "n_bins=10\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        if iteration_l:\n",
    "            i = iteration_l.pop(0)\n",
    "            col.hist(clean_loss_feat[i], bins=n_bins, alpha =0.5,label ='clean_loss')\n",
    "            col.hist(noise_loss_feat[i], bins=n_bins,alpha =0.5,label ='noisy_loss',color='orange')\n",
    "            col.set_xlabel(\"Loss\")\n",
    "            col.set_ylabel(\"Frequency\")\n",
    "            col.set_title('Iteration %i: Loss '%(i),y=1.05 )\n",
    "\n",
    "            col.legend(loc='best')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_perepo= num_labels/batch_size\n",
    "s_= int(it_perepo/2)\n",
    "\n",
    "iteration_l =list(range(0,100*int(it_perepo),max(s_,1)))\n",
    "\n",
    "fig, axes = plt.subplots(8, 5, tight_layout=True,sharex=True,sharey=True,figsize=(15.5,21))\n",
    "\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        if iteration_l:\n",
    "            i = iteration_l.pop(0)\n",
    "            col.hist(clean_lidfl2_feat[i], bins=n_bins, alpha =0.5,label ='clean_lid')\n",
    "            col.hist(noise_lidfl2_feat[i], bins=n_bins,alpha =0.5,label ='noisy_lid',color='orange')\n",
    "            col.set_xlabel(\"LID\")\n",
    "            col.set_ylabel(\"Frequency\")\n",
    "            col.set_title('Iteration %i: LID '%(i),y=1.05 )\n",
    "\n",
    "            col.legend(loc='best')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if w_type=='feat'or w_type=='n':\n",
    "    prefix = 'lid_feat_l2'\n",
    "else:\n",
    "    prefix = 'ce_loss'\n",
    "\n",
    "weight_log['w_{}_{}'.format(prefix,normal_)] = []\n",
    "w_all = weight_log['w_{}'.format(prefix)]\n",
    "\n",
    "for it in range(len(w_all)):\n",
    "    total_meta = (w_all[it]-w_all[it].min())/w_all[it].max()\n",
    "    total_meta /= torch.sum(total_meta)\n",
    "    weight_log['w_{}_{}'.format(prefix,normal_)].append(total_meta)\n",
    "\n",
    "\n",
    "w_noise_lid_logits_n, w_clean_lid_logits_n=get_g_clean_noisy(weight_log,'w_{}_{}'.format(prefix,normal_))\n",
    "std_ = [i.std() for i in weight_log['w_{}_{}'.format(prefix,normal_)]]\n",
    "\n",
    "\n",
    "s=len(w_all)\n",
    "\n",
    "noise_w_avg = [np.array(i).mean() for i in w_noise_lid_logits_n]\n",
    "noise_w_min = [np.array(i).min() for i in w_noise_lid_logits_n]\n",
    "noise_w_max = [np.array(i).max() for i in w_noise_lid_logits_n]\n",
    "\n",
    "clean_w_avg = [np.array(i).mean() for i in w_clean_lid_logits_n]\n",
    "clean_w_max = [np.array(i).max() for i in w_clean_lid_logits_n]\n",
    "clean_w_min = [np.array(i).min() for i in w_clean_lid_logits_n]\n",
    "\n",
    "clean_w_avg_s = metric_smoothing(clean_w_avg)\n",
    "clean_w_max_s =metric_smoothing(clean_w_max)\n",
    "\n",
    "noise_w_avg_s = metric_smoothing(noise_w_avg)\n",
    "noise_w_max_s = metric_smoothing(noise_w_max)\n",
    "std_s = metric_smoothing(std_)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(15,10),sharey=True)\n",
    "ax1, ax2,ax3,ax4 = axes.ravel()\n",
    "\n",
    "ax1.plot(clean_w_avg[:s],label='clean_w_avg')\n",
    "# ax1.plot(clean_w_max[:s],label='clean_w_max')\n",
    "# ax1.plot(clean_w_min,label='clean_w_min')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('Training Normalized Weights -Clean examples')\n",
    "ax1.set_ylabel('Normalized Weights')\n",
    "ax1.set_xlabel('iteration')\n",
    "\n",
    "ax2.plot(noise_w_avg[:s],label='noisy_w_avg')\n",
    "# ax2.plot(noise_w_max[:s],label='noisy_w_max')\n",
    "# ax2.plot(noise_w_min,label='noisy_w_min')\n",
    "ax2.legend()\n",
    "ax2.set_title('Training Normalized Weights -Noisy examples')\n",
    "ax1.set_ylabel('Normalized Weights')\n",
    "ax1.set_xlabel('iteration')\n",
    "\n",
    "\n",
    "ax3.plot(clean_w_avg_s[:s],label='clean_w_avg_s')\n",
    "# ax3.plot(clean_w_max_s[:s],label='clean_w_max_s')\n",
    "ax3.plot(noise_w_avg_s[:s],label='noisy_w_avg_s')\n",
    "ax3.plot(std_s[:s],label='std')\n",
    "\n",
    "# ax1.plot(clean_w_min,label='clean_w_min')\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_title('Training Normalized Weights (Smooth) ')\n",
    "ax3.set_ylabel('Normalized Weights')\n",
    "ax3.set_xlabel('iteration')\n",
    "\n",
    "\n",
    "ax4.plot(clean_w_avg[:s],label='clean_w_avg')\n",
    "ax4.plot(noise_w_avg[:s],label='noisy_w_avg')\n",
    "\n",
    "# ax4.plot(noise_w_max_s[:s],label='noisy_w_max_s')\n",
    "# ax2.plot(noise_w_min,label='noisy_w_min')\n",
    "ax4.legend()\n",
    "ax4.set_title('Training Normalized Weights (Raw)')\n",
    "ax4.set_ylabel('Normalized Weights')\n",
    "ax4.set_xlabel('iteration')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('------------------------------------------------',prefix)\n",
    "# w_noise_lid_logits, w_clean_lid_logits = get_g_clean_noisy(weight_log,'w_{}'.format(prefix))\n",
    "it_perepo= num_labels/batch_size\n",
    "s_= int(it_perepo/2)\n",
    "\n",
    "iteration_l =list(range(0,100*int(it_perepo),max(s_,1)))\n",
    "# iteration_l =list(range(0,200,2))\n",
    "\n",
    "# iteration_l=list(range(40,50))\n",
    "fig, axes = plt.subplots(8, 5, tight_layout=True,sharex=True,sharey=True,figsize=(15.5,21))\n",
    "n_bins=10\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        if iteration_l:\n",
    "            i = iteration_l.pop(0)\n",
    "            col.hist(w_clean_lid_logits_n[i], bins=n_bins, alpha =0.5,label ='clean_weight')\n",
    "            col.hist(w_noise_lid_logits_n[i], bins=n_bins,alpha =0.5,label ='noisy_weight',color='orange')\n",
    "            col.set_xlabel(\"weight\")\n",
    "            col.set_ylabel(\"Frequency\")\n",
    "            col.set_title('Iteration %i: Normalized weight '%(i),y=1.05 )\n",
    "\n",
    "            col.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_std,cov_loss= weight_log['feat_std'] ,weight_log['cov_loss']\n",
    "fig, axes = plt.subplots(1, 2, tight_layout=True,sharex=True,sharey=False)\n",
    "\n",
    "\n",
    "ax1.plot(feat_std, c='green',label='feat_std') \n",
    "ax1.set_ylabel(\"feat_std\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.legend()\n",
    "# ax1.set_ylim(0,0.28)\n",
    "ax1.set_title('feat_std loss')\n",
    "\n",
    "ax2.plot(cov_loss, c='blue',label='cov_loss') \n",
    "ax2.set_ylabel(\"cov_loss\")\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.legend()\n",
    "ax2.set_title('cov_loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37new",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
